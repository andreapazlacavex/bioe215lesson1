      BIOE215- Data Science 
      Class notes
      Andrea Paz-Lacavex

  #10/02/2023
  #Lesson 1 
  - Make sure files are saved before committing and pushing
  - " Commit is local and pull is remote [...] push is a remote operation, too, since it’s pushing your commits from the local repo to the remote one" Max C.
  - Write in the console when you first create a project: usethis::use_github()

  #10/09/2023
  #Lesson 2 - Computational thinking (to finish)
  
- command+shift+r to create subtitles
- "option"" + "-"" to create "<-"
- new built-in functions: min, max, sqrt, abs, max, min
- create new vector
    eg. numbers <- c(5, 2, 26, 8, 16)
- create new vector from another by space:
    eg. new_vector <- vector(vector[1:3])
- create new vector taking values (ie larger than) from an existing vector
    eg. height_over5 <- height[height>5]
- might need to add "na.rm=TRUE/FALSE", depending on the situation

Quarto:  brand new to literate programming
   Chapter 29: Quarto, sections 29.1-29.5 (Introduction through Code chunks), in R 4 Data Science by Hadley Wickham.
    - a Quarto file – a plain text file that has the extension .qmd
    -  [...] It contains three important types of content: An (optional) YAML header surrounded by ---s, Chunks of R code surrounded by ```, Text mixed with simple text formatting like # heading and _italics_.
    - [...] When you render the document, Quarto sends the .qmd file to knitr, https://yihui.org/knitr/, which executes all of the code chunks and creates a new markdown (.md) document which includes the code and its output. The markdown file generated by knitr is then processed by pandoc, https://pandoc.org, which is responsible for creating the finished file. 

  # 10/16/2023
  # Lesson 3 - Park downhill! (to finish)
  
  # EVERY NEW PROJECT need to: [remember to add "usethis::" at the beginning" .... if not, you can't push :( ]
    1) usethis::use_git()
    2) usethis::git_default_branch_rename()
    3) usethis::use_github()
    
  Functions in console view
  - Create folders:  dir.create("foldername")
  - Download data: download.file("https://ndownloader.figshare.com/files/2292169",
+               "data/portal_data_joined.csv") # comma points at a place we want it to be stored at
  - Create a new R script: file.edit("scratch/lesson3.R")
  
  Tidyverse
  - read_csv= tibble, more info than read.csv
  - head(surveys) # tibble details
    - length(surveys) 
    - nrow(surveys)
  - pipes %>% = "then"
  - select (dataframe, col names) # works on cols
  - filter # works on data IN the data frame
  - be careful with = and summarize (.groups="drop")... "because you dont want to go to stack overflow"
  - mutate (newcolname=oldcolname and calculations)
  - drop_na ()
  - group_by (col,col,col)
  - summarize (newcolname=whateveryouwantocalculatesuchasmeanmaxmin(oldcolname, .groups = "drop"")...amount=n()
  - arrange (desc(whatevercolyoureworkingon))
  - view() at the end of the pipeline if you want the result to show immediately, such as a table
  
  
  #10/23/2023
  #Lesson 4 - Functions
  
  - Functions are a "miniuniverse""
  - Key parts of functions: 
      name<- 
      key word= function 
      body{}
      parameter (s?)
  - First define the function! (will show in environment)
  - Parameter has no value beyond what you assignt to it. But make sure it is consistent throughout the function
  - key shortcut to move rows arround: place cursor on row, option+arrows wherever you wanna drop it.
  - Dont forget about adding return (result, or whatever you want to be published), at the end of the function
  
  Creating a project-setup function
  project_setup <- function () {
    dir.create("data")
    file.create("data/README.md")
    writeLines("This folder contains data", 
             "data/README.md")
    return("¡Éxito en la misión!")
  }
project_setup()
  
  
  From assessment: Where do birds hatch?
  - Remember to check Lesson 4 for a great example on how to simulate data! (will need for grazing experiments)
  - slice (1)=  is used to select the first row of a data frame or tibble.
  - Split-apply-combine is a strategy used to work on subsets of the data and perform operations such as summarize, filter, mutate, etc, and then combine again.
      "Split: The data is divided into groups based on some criteria. For example, you might split a dataset by categories, like grouping students by their grades, or by some other characteristic like age range.
      Apply: An operation or function is applied to each group independently. This could involve calculations, summarizations, or any other kind of data manipulation.
      Combine: The results from each group are combined back together into a single data structure. This could mean aggregating summary statistics, merging datasets, or any other kind of combining operation."
      
      
  #10/30/2023 Lesson 5 - Troubleshooting (to do)



  #11/06/2023 Lesson 6 - Wrap up skills portion
      
      
  

  
  